---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# %matplotlib inline
# %autosave 0
import tensorflow as tf
import math
import keras as kr
import numpy as np
import matplotlib.pyplot as plt
import healpy as hp
#import seaborn as sb
#import pandas as pd
from keras.models import Sequential
import nnhealpix as nn
import nnhealpix.layers
import sklearn.utils as sku
```

## Création des $C_\ell$

```{python}
l=np.linspace(5.0, 100.0, 2000)
l_p= (50.0-5.0)*np.random.random_sample(10000,) + 5
moy_l_p = np.mean(l_p)
ecart_l_p = np.sqrt(np.var(l_p))
sigma_p=5.0
print(l.shape, l_p.shape)
print(moy_l_p, ecart_l_p)
print(np.max(l_p))
```

```{python}
C_l=np.zeros((len(l),len(l_p)))
for i in range (len(l)):
    for j in range (len(l_p)):
        C_l[i,j]=np.exp(-((l[i]-l_p[j])**2.0)/(2.0*sigma_p**2.0))+10.0**(-5.0)
```

```{python}
C_l.shape
for i in range(10):
    plt.plot(l, C_l[:, i])
```

fig1=plt.figure(1,figsize=(10,10),edgecolor='black')
color=plt.cbar()
color.set_label('$\ell _p$')
plt.ylabel('$C_\ell$')
plt.xlabel('Multipole $\ell$')
for i in range (len(l_p)):
    plt.plot(l,C_l)
plt.show


## Mapisation des $C_ \ell$

```{python}
nside = 16
Maps = []
for j in range (len(l_p)) :
    Map = hp.sphtfunc.synfast(C_l[:,j], nside)
    Maps = np.append(Maps,Map)
Maps = Maps.reshape((12*nside**2, len(l_p)))

```

for i in range (len(l_p)-1):
    for j in range (len(l_p)-1):
        if i != j:
            for k in range (len(Maps[:,0])):
                if Maps[k,i] == Maps[k,j]:
                    print("Il y a une erreur entre ", k," ", i, " et ", k," ", j )

```{python}
moy_Maps = np.mean(Maps)
ecart_Maps = np.sqrt(np.var(Maps))
Max_Maps = np.abs(Maps).max()
Maps = (Maps-moy_Maps)/(np.abs(Maps).max())
```

```{python}
print(Maps.shape)
print(ecart_Maps)
print(np.abs(Maps).max())
print(Maps)
```

hp.mollview(X_train[1,:,0])

```{python}
plt.plot(y_train)
```

# Machine Learning


## Préparation des données

```{python}
Ntest = 100
Ntrain = len(l_p)-Ntest
# Normalisation des sorties
Max_l_p=np.abs(l_p).max()
NNl_p = (l_p-5)/(50.0 - 5.0)
# Attribution des valeurs d'entrées et de sorties pour l'entrainement et les tests
X_train = Maps[:, 0:(Ntrain)]
y_train = l_p[0: (Ntrain)]
X_test = Maps[:, (Ntrain):(Ntrain + Ntest)]
y_test = l_p[(Ntrain) : (Ntrain + Ntest)]

print(y_train.shape, y_test.shape)
print(np.abs(NNl_p).max())
```

```{python}
print(y_train)
```

```{python}
seed = 7
np.random.seed(seed)
shape=(len(Maps[:,0]), 1)
num_classes = 1 #y_train.shape[1]
# Mise en forme adequate
X_train = X_train.T
X_test = X_test.T
print(X_train.shape, shape, X_test.shape)
X_train = X_train.reshape(X_train.shape[0], len(X_train[0]), 1)
X_test = X_test.reshape(X_test.shape[0], len(X_test[0]), 1)
print(X_train.shape, shape, X_test.shape)
```

## NBB layers


def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

```{python}
inputs=kr.layers.Input(shape)
x=inputs
for i in range (int(math.log(nside,2))):
#Recog of the neighbours & Convolution
    print(int(nside/(2**(i))), int(nside/(2**(i+1))))
    x = nnhealpix.layers.ConvNeighbours(int(nside/(2**(i))), filters=32, kernel_size=9)(x)
    x = kr.layers.Activation('relu')(x)
#Degrade
    x = nnhealpix.layers.MaxPooling(int(nside/(2**(i))), int(nside/(2**(i+1))))(x)
#Sortie des NBB
x = kr.layers.Dropout(0.2)(x)
x = kr.layers.Flatten()(x)
x = kr.layers.Dense(48)(x)
x = kr.layers.Activation('relu')(x)
x = kr.layers.Dense(1)(x)

out=kr.layers.Activation('relu')(x)
```

## Model

```{python}
# Création et mise en place du model
model = kr.models.Model(inputs=inputs, outputs=out)
model.compile(loss=kr.losses.mse, optimizer='adam', metrics=[kr.metrics.mean_absolute_percentage_error])
model.summary()
```

## Training

```{python}
# Entrainement du model
hist = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split = 0.1, verbose = 1, shuffle = True)
scores = model.evaluate(X_test, y_test, verbose=0)
print("CNN Error: %.2f%%" % (100-scores[1]*100))
```

```{python}
prediction = model.predict(X_test)
print(prediction.shape)
```

```{python}
#prediction[:,0]=(50.0-5.0)*prediction[:,0]+5.0
print(prediction)
```

print(X_test)
print(y_test)

```{python}
prediction.shape
diff=prediction-y_test
```

```{python}
# Comparaison entre les valeurs obtenues et les valeurs recherchées
fig1=plt.figure(1,figsize=(10,10),edgecolor='gray')
plt.ylabel('$\ell _p$ recherchés et $\ell _p$ prédit')
plt.xlabel('')
plt.title('Comparatif des données recherchées et prédite par le modèle')
for i in range (len(diff[:,0])):
    plt.plot(i, prediction[i,0], color ='blue',marker='o')
    plt.plot(i, l_p[i], color ='red',marker='+')
plt.legend(['$\ell _p$ prédits','$\ell _p$ recherchés' ],loc = 2)
plt.show()
```

```{python}
plt.plot(l_p[:20], prediction[:, 0], '.')
```

```{python}

```

```{python}

```
