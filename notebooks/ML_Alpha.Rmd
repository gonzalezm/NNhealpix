---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# %autosave 0
# %matplotlib inline
import tensorflow as tf
import math
import keras as kr
import numpy as np
import matplotlib.pyplot as plt
import healpy as hp
#import seaborn as sb
#import pandas as pd
from keras.models import Sequential
import nnhealpix as nn
import nnhealpix.layers
```

## Création des $C_\ell$

```{python}
l=np.linspace(5.0, 100.0, 200)
l_p=np.linspace(5.0, 50.0, 10010)
sigma_p=5.0
print(l.shape, l_p.shape)
```

```{python}
C_l=np.zeros((len(l),len(l_p)))
for i in range (len(l)):
    for j in range (len(l_p)):
        C_l[i,j]=np.exp(-((l[i]-l_p[j])**2.0)/(2.0*sigma_p**2.0))+10.0**(-5.0)
```

```{python}
#fig1=plt.figure(1,figsize=(10,10),edgecolor='black')
#color=plt.cbar()
#color.set_label('$\ell _p$')
#plt.ylabel('$C_\ell$')
#plt.xlabel('Multipole $\ell$')
#for i in range (len(l_p)):
#    plt.plot(l,C_l)
#plt.show
```

## Mapisation des $C_ \ell$

```{python}
nside = 16
Maps = []
for j in range (len(l_p)) :
    Map = hp.sphtfunc.synfast(C_l[:,j], nside)
    Maps = np.append(Maps,Map)
Maps=Maps.reshape((12*nside**2, len(l_p)))
print(Maps)
print(Maps.shape)
```

## Préparation du ML

```{python}
Ntrain = 10000-100
Ntest = 910
X_train = Maps[:,0:(Ntrain)]
y_train = l_p[0:(Ntrain)]
X_test = Maps[:,(Ntrain):(Ntrain+Ntest)]
y_test = l_p[(Ntrain):(Ntrain+Ntest)]
print(y_train.shape, y_test.shape)
y_train = kr.utils.to_categorical(y_train)
y_test = kr.utils.to_categorical(y_test)
y_test = y_test[:,:50]
#y_train = y_train.T
#y_test = y_test.T
print(y_train.shape, y_test.shape)
```

```{python}
seed = 7
np.random.seed(seed)
shape=(len(Maps[:,0]), 1)
num_classes = y_train.shape[1]
X_train = X_train.T
X_test = X_test.T
print(X_train.shape, shape, X_test.shape)
X_train = X_train.reshape(X_train.shape[0], len(X_train[0]), 1)
X_test = X_test.reshape(X_test.shape[0], len(X_test[0]), 1)
print(X_train.shape, shape, X_test.shape)
```

## NBB layers

```{python}
inputs=kr.layers.Input(shape)
#x = nnhealpix.layers.ConvNeighbours(nside, filters=32, kernel_size=9)(inputs)
for i in range (int(math.log(nside,2))):
#   Recog of the neighbours & Convolution
    x = nnhealpix.layers.ConvNeighbours(int(nside/(2**(i))), filters=32, kernel_size=9)(inputs)
    x = kr.layers.Activation('relu')(x)
#   Degrade
    x = nnhealpix.layers.MaxPooling(int(nside/(2**(i))), int(nside/(2**(i+1))))(x)

x = kr.layers.Dropout(0.2)(x)
x = kr.layers.Flatten()(x)
x = kr.layers.Dense(128)(x)
x = kr.layers.Activation('relu')(x)
x = kr.layers.Dense(num_classes)(x)

out=kr.layers.Activation('softmax')(x)
```

### Model

```{python}
model = kr.models.Model(inputs=inputs, outputs=out)
model.compile(loss=kr.losses.mse, optimizer='adam', metrics=['accuracy'])
model.summary()
```

### Training

```{python}
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=100, verbose=1)
scores = model.evaluate(X_test, y_test, verbose=0)
print("CNN Error: %.2f%%" % (100-scores[1]*100))
```

```{python}

```
