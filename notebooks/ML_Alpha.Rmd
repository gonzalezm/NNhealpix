---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# %matplotlib inline
import tensorflow as tf
import math
import keras as kr
import numpy as np
import matplotlib.pyplot as plt
import healpy as hp
#import seaborn as sb
#import pandas as pd
from keras.models import Sequential
import nnhealpix as nn
import nnhealpix.layers
```

## Création des $C_\ell$

```{python}
l=np.linspace(5.0, 100.0, 2000)
l_p= (50.0-5.0)*np.random.random_sample(10010,) + 5
moy_l_p = np.mean(l_p)
ecart_l_p = np.sqrt(np.var(l_p))
sigma_p=5.0
print(l.shape, l_p.shape)
print(moy_l_p, ecart_l_p)
```

```{python}
C_l=np.zeros((len(l),len(l_p)))
for i in range (len(l)):
    for j in range (len(l_p)):
        C_l[i,j]=np.exp(-((l[i]-l_p[j])**2.0)/(2.0*sigma_p**2.0))+10.0**(-5.0)
```

fig1=plt.figure(1,figsize=(10,10),edgecolor='black')
color=plt.cbar()
color.set_label('$\ell _p$')
plt.ylabel('$C_\ell$')
plt.xlabel('Multipole $\ell$')
for i in range (len(l_p)):
    plt.plot(l,C_l)
plt.show


## Mapisation des $C_ \ell$

```{python}
nside = 16
Maps = []
for j in range (len(l_p)) :
    Map = hp.sphtfunc.synfast(C_l[:,j], nside)
    Maps = np.append(Maps,Map)
Maps = Maps.reshape((12*nside**2, len(l_p)))
print(np.abs(Maps).max())
print(Maps.shape)
```

```{python}
moy_Maps = np.mean(Maps)
ecart_Maps = np.sqrt(np.var(Maps))
Max_Maps = np.abs(Maps).max()
Maps = (Maps-moy_Maps)/(np.abs(Maps).max())
```

```{python}
print(moy_Maps)
print(ecart_Maps)
print(np.abs(Maps).max())
```

# Machine Learning


## Préparation des données

```{python}
Ntrain = 10000-100
Ntest = 110
Max_l_p=np.abs(l_p).max()
NNl_p = (l_p-moy_l_p)/(np.abs(l_p).max())
X_train = Maps[:,0:(Ntrain)]
y_train = NNl_p[0:(Ntrain)]
X_test = Maps[:,(Ntrain):(Ntrain+Ntest)]
y_test = NNl_p[(Ntrain):(Ntrain+Ntest)]
print(y_train.shape, y_test.shape)
y_train = kr.utils.to_categorical(y_train)
y_test = kr.utils.to_categorical(y_test)
#y_test = y_test[:,:50]
#y_train = y_train.T
#y_test = y_test.T
print(y_train.shape, y_test.shape)
print(np.abs(NNl_p).max())
```

```{python}
seed = 7
np.random.seed(seed)
shape=(len(Maps[:,0]), 1)
num_classes = y_train.shape[1]
X_train = X_train.T
X_test = X_test.T
print(X_train.shape, shape, X_test.shape)
X_train = X_train.reshape(X_train.shape[0], len(X_train[0]), 1)
X_test = X_test.reshape(X_test.shape[0], len(X_test[0]), 1)
print(X_train.shape, shape, X_test.shape)
```

## NBB layers

```{python}
inputs=kr.layers.Input(shape)
#x = nnhealpix.layers.ConvNeighbours(nside, filters=32, kernel_size=9)(inputs)
for i in range (int(math.log(nside,2))):
#   Recog of the neighbours & Convolution
    x = nnhealpix.layers.ConvNeighbours(int(nside/(2**(i))), filters=32, kernel_size=9)(inputs)
    x = kr.layers.Activation('relu')(x)
#   Degrade
    x = nnhealpix.layers.MaxPooling(int(nside/(2**(i))), int(nside/(2**(i+1))))(x)

x = kr.layers.Dropout(0.2)(x)
x = kr.layers.Flatten()(x)
x = kr.layers.Dense(128)(x)
x = kr.layers.Activation('relu')(x)
x = kr.layers.Dense(num_classes)(x)

out=kr.layers.Activation('softmax')(x)
```

## Model

```{python}
model = kr.models.Model(inputs=inputs, outputs=out)
model.compile(loss=kr.losses.mse, optimizer='adam', metrics=['accuracy'])
model.summary()
```

## Training

```{python}
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=500, verbose=1)
scores = model.evaluate(X_test, y_test, verbose=0)
print("CNN Error: %.2f%%" % (100-scores[1]*100))
```

```{python}
prediction = model.predict(X_test)*ecart_l_p+moy_l_p
```

```{python}
print(X_test)
print(y_test)
```

```{python}
prediction.shape
diff=prediction-
```

```{python}

```
